{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "jupyter_black.load(line_length=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_excel(\"量表最终版.xlsx\")\n",
    "scores = scores[[\"提交答卷时间\", \"账号\", \"PHQ-9总分\", \"GAD-7总分\", \"AIS总分\"]]\n",
    "\n",
    "scores[\"提交答卷时间\"] = pd.to_datetime(scores[\"提交答卷时间\"], format=\"%Y/%m/%d %H:%M:%S\")\n",
    "scores[\"提交答卷时间\"] = scores[\"提交答卷时间\"].dt.date\n",
    "\n",
    "scores = scores[(scores[\"账号\"] == \"gzj\") | (scores[\"账号\"] == \"hm\")]\n",
    "scores.rename(\n",
    "    columns={\n",
    "        \"提交答卷时间\": \"Date\",\n",
    "        \"账号\": \"SID\",\n",
    "        \"PHQ-9总分\": \"PHQ-9\",\n",
    "        \"GAD-7总分\": \"GAD-7\",\n",
    "        \"AIS总分\": \"AIS\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "scores.sort_values(by=\"Date\", inplace=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_scores(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    interpolated_dfs = []\n",
    "    for sid, group in df.groupby(\"SID\"):\n",
    "        group = group.set_index(\"Date\")\n",
    "\n",
    "        for col in [\"PHQ-9\", \"GAD-7\", \"AIS\"]:\n",
    "            group[col] = pd.to_numeric(group[col], errors=\"coerce\")\n",
    "\n",
    "        group = group.resample(\"D\").interpolate(method=\"time\")\n",
    "        group[\"SID\"] = sid\n",
    "        interpolated_dfs.append(group)\n",
    "\n",
    "    final_df = pd.concat(interpolated_dfs)\n",
    "    final_df = final_df.reset_index()\n",
    "    return final_df\n",
    "\n",
    "\n",
    "scores = interpolate_scores(scores.copy())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scores(scores: pd.DataFrame, input_dir: str = \"data_csv\", output_dir: str = \"data_add\",bar:bool=False):\n",
    "    scores[\"Date\"] = pd.to_datetime(scores[\"Date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    feature_dirs=tqdm(os.listdir(input_dir), desc=\"Processing by features\") if bar else os.listdir(input_dir)\n",
    "\n",
    "    for feature_dir in feature_dirs:\n",
    "        feature_path = os.path.join(input_dir, feature_dir)\n",
    "        if os.path.isdir(feature_path):\n",
    "            output_feature_path = os.path.join(output_dir, feature_dir)\n",
    "            os.makedirs(output_feature_path, exist_ok=True)\n",
    "\n",
    "            for filename in os.listdir(feature_path):\n",
    "                if filename.endswith(\".csv\"):\n",
    "                    file_path = os.path.join(feature_path, filename)\n",
    "                    date_str, _ = os.path.splitext(filename)\n",
    "                    date_str = pd.to_datetime(date_str).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                    df = pd.read_csv(file_path, dtype=str)\n",
    "                    unique_sids = df[\"SID\"].unique()\n",
    "                    for sid in unique_sids:\n",
    "                        match = scores[(scores[\"SID\"] == sid) & (scores[\"Date\"] == date_str)]\n",
    "\n",
    "                        if not match.empty:\n",
    "                            phq9 = round(match[\"PHQ-9\"].iloc[0], 4)\n",
    "                            gad7 = round(match[\"GAD-7\"].iloc[0], 4)\n",
    "                            ais = round(match[\"AIS\"].iloc[0], 4)\n",
    "\n",
    "                            df.loc[df[\"SID\"] == sid, \"PHQ-9\"] = phq9\n",
    "                            df.loc[df[\"SID\"] == sid, \"GAD-7\"] = gad7\n",
    "                            df.loc[df[\"SID\"] == sid, \"AIS\"] = ais\n",
    "\n",
    "                    output_file_path = os.path.join(output_feature_path, filename)\n",
    "                    df.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_scores(scores,bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def conv_pool(feature: str, input_dir: str = \"data_add\", output_dir: str = \"dataset\", bar: bool = False):\n",
    "    data_path = os.path.join(input_dir, feature)\n",
    "    dates_path = tqdm(os.listdir(data_path), desc=\"Processing by dates\") if bar else os.listdir(data_path)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"data_add\"\n",
    "output_dir = \"dataset\"\n",
    "feature = \"ACCELERATION\"\n",
    "\n",
    "# data_path = os.path.join(input_dir, feature)\n",
    "# dates_path = tqdm(os.listdir(data_path), desc=\"Processing by dates\")\n",
    "# for date_path in dates_path:\n",
    "#     date_str=date_path\n",
    "#     date_path = os.path.join(data_path, date_path)\n",
    "#     date = pd.read_csv(date_path)\n",
    "#     date = clean_incremental_timestamps(date)\n",
    "#     processed_df = process_time_window(date.copy(), csv_file_path, window=\"1min\", interpolate=True)\n",
    "\n",
    "date = pd.read_csv(\"data_add/ACCELERATION/2024.11.05.csv\")\n",
    "print(date.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
